{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install keras.utils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iegQqtNOwOWa",
        "outputId": "cbb9f9cf-c554-4678-d46c-0a07cf2bb8a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras.utils\n",
            "  Downloading keras-utils-1.0.13.tar.gz (2.4 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Keras>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from keras.utils) (2.15.0)\n",
            "Building wheels for collected packages: keras.utils\n",
            "  Building wheel for keras.utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras.utils: filename=keras_utils-1.0.13-py3-none-any.whl size=2631 sha256=d8a60dcbe1c93e122b0f29c095e5bf47e38290b20cd9daa889881d1ec1a72e01\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/c0/b3/0c332de4fd71f3733ea6d61697464b7ae4b2b5ff0300e6ca7a\n",
            "Successfully built keras.utils\n",
            "Installing collected packages: keras.utils\n",
            "Successfully installed keras.utils-1.0.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/content/news_data_with_text.csv'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n"
      ],
      "metadata": {
        "id": "sWURUGqNyv5F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import model_from_json\n",
        "import numpy as np\n",
        "from nltk import word_tokenize\n",
        "from numpy import array\n",
        "from keras.models import Model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Input\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Embedding\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from keras.preprocessing import sequence\n",
        "from keras.layers import Dense\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import re,codecs\n",
        "from nltk.corpus import stopwords\n",
        "from bs4 import BeautifulSoup\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from tqdm import tqdm\n",
        "from keras.layers import RepeatVector\n",
        "from keras.layers import TimeDistributed"
      ],
      "metadata": {
        "id": "hu3tn2eYzKeX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
        "\n",
        "                           \"didn't\": \"did not\", \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
        "\n",
        "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
        "\n",
        "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
        "\n",
        "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
        "\n",
        "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
        "\n",
        "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
        "\n",
        "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
        "\n",
        "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
        "\n",
        "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
        "\n",
        "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
        "\n",
        "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
        "\n",
        "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
        "\n",
        "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
        "\n",
        "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
        "\n",
        "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
        "\n",
        "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
        "\n",
        "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
        "\n",
        "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
        "\n",
        "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
        "\n",
        "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
        "\n",
        "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
        "\n",
        "                           \"you're\": \"you are\", \"you've\": \"you have\"}"
      ],
      "metadata": {
        "id": "nr8UZ5WINHK_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy\n",
        "!pip install matplotlib\n",
        "!pip install scipy\n",
        "!pip install -U scikit-learn\n",
        "!pip install seaborn\n",
        "!pip3 install keras\n",
        "!pip3 show keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkOzhaoT2Vxy",
        "outputId": "27b99508-eaa1-4d43-c3f7-404cbf68de3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.0)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.13.1)\n",
            "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /usr/local/lib/python3.10/dist-packages (from seaborn) (1.25.2)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.10/dist-packages (from seaborn) (2.0.3)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.10/dist-packages (from seaborn) (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Name: keras\n",
            "Version: 2.15.0\n",
            "Summary: Deep learning for humans.\n",
            "Home-page: https://keras.io/\n",
            "Author: Keras team\n",
            "Author-email: keras-users@googlegroups.com\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: \n",
            "Required-by: keras-utils, tensorflow\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"/content/news_data_with_text.csv\",encoding = \"ISO-8859-1\")\n",
        "new_df=df['Text']\n",
        "new_df.to_csv('summary.csv',encoding = \"ISO-8859-1\")\n",
        "print(new_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QZde5wM3L28",
        "outputId": "7cb37843-9270-4a26-e463-3d4223751932"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0     Science & technology | Generative AI Large, cr...\n",
            "1     The Reddit post has accumulated more than 8,70...\n",
            "2     The launch of a new branch of artificial intel...\n",
            "3     ChatGPT has kicked off an AI revolution. Compa...\n",
            "4     Today, it seems like AI chatbots are everywher...\n",
            "5     The week's best writing on technology and more...\n",
            "6     What is Auto-GPT and why does it matter?\\n\\nSi...\n",
            "7     Artificial intelligence is making some major l...\n",
            "8     ChatGPT has raised the bar for what we believe...\n",
            "9     John Schulman cofounded the ambitious software...\n",
            "10    ChatGPT, OpenAI's large language model for cha...\n",
            "11    Why did this happen?\\n\\nPlease make sure your ...\n",
            "12    As the field of artificial intelligence contin...\n",
            "13    ChatGPT fans need to adopt a \"defensive mindse...\n",
            "14    Through the release of its API, OpenAI has ope...\n",
            "15    Ever since it came under the public eye, ChatG...\n",
            "16    In today's fast-paced digital landscape, chatb...\n",
            "17    ChatGPT is a text-based form of AI that will g...\n",
            "18    GPT-4 is the latest large multimodal model fro...\n",
            "19    ChatGPT has been taking the world by storm sin...\n",
            "Name: Text, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"/content/news_data_with_text.csv\",encoding = \"ISO-8859-1\")\n",
        "columns=df.columns\n",
        "df.drop_duplicates(keep='first',inplace=True)\n",
        "df.dropna(axis=0,inplace=True)"
      ],
      "metadata": {
        "id": "RNGrNxRpJNZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "def text_cleaner(Text):\n",
        "  newString = Text.lower()\n",
        "  #PARSER lxml and beautifulsoup is used to remove the html tags\n",
        "  newString = BeautifulSoup(newString, \"lxml\").Text\n",
        "  # Remove any text inside parentheses and re.sub has exactly 3 arguments\n",
        "  newString = re.sub(r'\\([^)]*\\)', '', str(newString))\n",
        "  newString = re.sub('\"','', newString)\n",
        "  newString = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in newString.split(\" \")])\n",
        "  newString = re.sub(r\"'s\\b\",\"\",newString)\n",
        "  newString = re.sub(\"[^a-zA-Z]\", \" \", newString)\n",
        "  tokens = [w for w in newString.split() if not w in stop_words]\n",
        "  long_words=[]\n",
        "  for i in tokens:\n",
        "    if len(i)>1:\n",
        "      long_words.append(i)\n",
        "  return (\" \".join(long_words)).strip()\n",
        "\n",
        "cleaned_text = []\n",
        "for t in df['Text']:\n",
        "  cleaned_text.append(text_cleaner(t))\n",
        "  #print('done')\n",
        "def summary_cleaner(Text):\n",
        "  newString = re.sub('\"','', Text)\n",
        "  newString = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in newString.split(\" \")])\n",
        "  newString = re.sub(r\"'s\\b\",\"\",newString)\n",
        "  newString = re.sub(\"[^a-zA-Z]\", \" \", newString)\n",
        "  newString = newString.lower()\n",
        "  tokens=newString.split()\n",
        "  newString=''\n",
        "  for i in tokens:\n",
        "    if len(i)>=3:\n",
        "      newString=newString+i+' '\n",
        "  return newString\n",
        "\n",
        "#Call the above function\n",
        "cleaned_summary = []\n",
        "for t in df['Text']:\n",
        "  cleaned_summary.append(summary_cleaner(t))\n",
        "\n",
        "\n",
        "df['cleaned_text']=cleaned_text\n",
        "df['cleaned_summary']=cleaned_summary\n",
        "df.replace('', np.nan, inplace=True)\n",
        "df.dropna(axis=0,inplace=True)\n",
        "print(\"done\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92qblf9zNe8w",
        "outputId": "fc73535f-e584-4152-98fb-d484f8526a18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "id": "u4cenZxIWRl5",
        "outputId": "4ddc44b1-d73a-4fed-a8ff-5441aada5702"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0                                              Title  \\\n",
              "0           0  Large, creative AI models will transform lives...   \n",
              "1           1  Student Who Never Attended Classes Claims To H...   \n",
              "2           2               ChatGPT sparks AI investment bonanza   \n",
              "3           3            7 best ChatGPT alternatives I've tested   \n",
              "4           4  ChatGPT Comes to Minecraft AI Mobs, Here's How...   \n",
              "\n",
              "            Media       Update                   Timestamp  \\\n",
              "0   The Economist   8 mins ago  2023-04-22 23:55:39.052920   \n",
              "1            NDTV  1 hours ago  2023-04-22 23:03:39.869218   \n",
              "2              DW   1 hour ago  2023-04-22 23:03:39.851599   \n",
              "3     Tom's Guide  2 hours ago  2023-04-22 22:03:39.869716   \n",
              "4  Tom's Hardware  2 hours ago  2023-04-22 22:03:39.859487   \n",
              "\n",
              "                                         Description  \\\n",
              "0  GPT-3 is able to process a maximum of 2,048 to...   \n",
              "1  In the latest viral claim, ChatGPT helped a st...   \n",
              "2  The launch of a new branch of artificial intel...   \n",
              "3  ChatGPT has kicked off an AI revolution. Compa...   \n",
              "4  Have a fascinating chat with an Enderman, Cree...   \n",
              "\n",
              "                                                Link  \\\n",
              "0  https://www.economist.com/interactive/science-...   \n",
              "1  https://www.ndtv.com/feature/student-who-never...   \n",
              "2  https://www.dw.com/en/chatgpt-sparks-ai-invest...   \n",
              "3  https://www.tomsguide.com/features/chatgpt-alt...   \n",
              "4  https://www.tomshardware.com/how-to/chatgpt-mi...   \n",
              "\n",
              "                                               Image  \\\n",
              "0  data:image/gif;base64,R0lGODlhAQABAIAAAP//////...   \n",
              "1  data:image/gif;base64,R0lGODlhAQABAIAAAP//////...   \n",
              "2  data:image/gif;base64,R0lGODlhAQABAIAAAP//////...   \n",
              "3  data:image/gif;base64,R0lGODlhAQABAIAAAP//////...   \n",
              "4  data:image/gif;base64,R0lGODlhAQABAIAAAP//////...   \n",
              "\n",
              "                                                Text cleaned_text  \\\n",
              "0  Science & technology | Generative AI Large, cr...         None   \n",
              "1  The Reddit post has accumulated more than 8,70...         None   \n",
              "2  The launch of a new branch of artificial intel...         None   \n",
              "3  ChatGPT has kicked off an AI revolution. Compa...         None   \n",
              "4  Today, it seems like AI chatbots are everywher...         None   \n",
              "\n",
              "                                     cleaned_summary  \n",
              "0  science technology generative large creative m...  \n",
              "1  the reddit post has accumulated more than upvo...  \n",
              "2  the launch new branch artificial intelligence ...  \n",
              "3  chatgpt has kicked off revolution companies fr...  \n",
              "4  today seems like chatbots are everywhere from ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8d773b6f-d46c-4cd8-b01b-e41df90855ba\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Title</th>\n",
              "      <th>Media</th>\n",
              "      <th>Update</th>\n",
              "      <th>Timestamp</th>\n",
              "      <th>Description</th>\n",
              "      <th>Link</th>\n",
              "      <th>Image</th>\n",
              "      <th>Text</th>\n",
              "      <th>cleaned_text</th>\n",
              "      <th>cleaned_summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Large, creative AI models will transform lives...</td>\n",
              "      <td>The Economist</td>\n",
              "      <td>8 mins ago</td>\n",
              "      <td>2023-04-22 23:55:39.052920</td>\n",
              "      <td>GPT-3 is able to process a maximum of 2,048 to...</td>\n",
              "      <td>https://www.economist.com/interactive/science-...</td>\n",
              "      <td>data:image/gif;base64,R0lGODlhAQABAIAAAP//////...</td>\n",
              "      <td>Science &amp; technology | Generative AI Large, cr...</td>\n",
              "      <td>None</td>\n",
              "      <td>science technology generative large creative m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Student Who Never Attended Classes Claims To H...</td>\n",
              "      <td>NDTV</td>\n",
              "      <td>1 hours ago</td>\n",
              "      <td>2023-04-22 23:03:39.869218</td>\n",
              "      <td>In the latest viral claim, ChatGPT helped a st...</td>\n",
              "      <td>https://www.ndtv.com/feature/student-who-never...</td>\n",
              "      <td>data:image/gif;base64,R0lGODlhAQABAIAAAP//////...</td>\n",
              "      <td>The Reddit post has accumulated more than 8,70...</td>\n",
              "      <td>None</td>\n",
              "      <td>the reddit post has accumulated more than upvo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>ChatGPT sparks AI investment bonanza</td>\n",
              "      <td>DW</td>\n",
              "      <td>1 hour ago</td>\n",
              "      <td>2023-04-22 23:03:39.851599</td>\n",
              "      <td>The launch of a new branch of artificial intel...</td>\n",
              "      <td>https://www.dw.com/en/chatgpt-sparks-ai-invest...</td>\n",
              "      <td>data:image/gif;base64,R0lGODlhAQABAIAAAP//////...</td>\n",
              "      <td>The launch of a new branch of artificial intel...</td>\n",
              "      <td>None</td>\n",
              "      <td>the launch new branch artificial intelligence ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>7 best ChatGPT alternatives I've tested</td>\n",
              "      <td>Tom's Guide</td>\n",
              "      <td>2 hours ago</td>\n",
              "      <td>2023-04-22 22:03:39.869716</td>\n",
              "      <td>ChatGPT has kicked off an AI revolution. Compa...</td>\n",
              "      <td>https://www.tomsguide.com/features/chatgpt-alt...</td>\n",
              "      <td>data:image/gif;base64,R0lGODlhAQABAIAAAP//////...</td>\n",
              "      <td>ChatGPT has kicked off an AI revolution. Compa...</td>\n",
              "      <td>None</td>\n",
              "      <td>chatgpt has kicked off revolution companies fr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>ChatGPT Comes to Minecraft AI Mobs, Here's How...</td>\n",
              "      <td>Tom's Hardware</td>\n",
              "      <td>2 hours ago</td>\n",
              "      <td>2023-04-22 22:03:39.859487</td>\n",
              "      <td>Have a fascinating chat with an Enderman, Cree...</td>\n",
              "      <td>https://www.tomshardware.com/how-to/chatgpt-mi...</td>\n",
              "      <td>data:image/gif;base64,R0lGODlhAQABAIAAAP//////...</td>\n",
              "      <td>Today, it seems like AI chatbots are everywher...</td>\n",
              "      <td>None</td>\n",
              "      <td>today seems like chatbots are everywhere from ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8d773b6f-d46c-4cd8-b01b-e41df90855ba')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8d773b6f-d46c-4cd8-b01b-e41df90855ba button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8d773b6f-d46c-4cd8-b01b-e41df90855ba');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5435ad03-5edf-4b18-9931-c941acc2aa2e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5435ad03-5edf-4b18-9931-c941acc2aa2e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5435ad03-5edf-4b18-9931-c941acc2aa2e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5,\n        \"min\": 0,\n        \"max\": 19,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          0,\n          17,\n          15\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"Large, creative AI models will transform lives and labour markets\",\n          \"Chat GPT: We asked the AI bot to write articles about Oxford\",\n          \"18 Best ChatGPT Chrome Extensions You Need to Check Out\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Media\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 16,\n        \"samples\": [\n          \"The Economist\",\n          \"NDTV\",\n          \"Engadget\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Update\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"8 mins ago\",\n          \"1 hours ago\",\n          \"6 hours ago\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Timestamp\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"2023-04-22 23:55:39.052920\",\n          \"2023-04-22 00:03:40.386757\",\n          \"2023-04-22 00:03:40.397256\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"GPT-3 is able to process a maximum of 2,048 tokens at a time, which is around the length of a long article in The Economist. GPT-4, by contrast,...\",\n          \"Chat GPT is a text-based form of AI that will give an answer to any question you pose.\",\n          \"Love ChatGPT and want to extend its functionality? Here are the 18 best ChatGPT Google Chrome extensions that make the chatbot more useful.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Link\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"https://www.economist.com/interactive/science-and-technology/2023/04/22/large-creative-ai-models-will-transform-how-we-live-and-work\",\n          \"https://www.oxfordmail.co.uk/news/23471833.chat-gpt-asked-ai-bot-write-articles-oxford/\",\n          \"https://beebom.com/best-chatgpt-chrome-extensions/\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Image\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"Science & technology | Generative AI Large, creative AI models will transform lives and labour markets They bring enormous promise and peril. In the first of three special articles we explain how they work\\n\\nImage: George Wylesol\\n\\nS ince November 2022, when Open AI , the company which makes Chat GPT , first opened the chatbot to the public, there has been little else that the tech elite has wanted to talk about. As this article was being written, the founder of a London technology company messaged your correspondent unprompted to say that this kind of AI is \\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u009cessentially all I\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u0099m thinking about these days\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u009d. He says he is in the process of redesigning his company, valued at many hundreds of millions of dollars, around it. He is not alone.\\n\\nGPT embodies TSMC , a Taiwanese semiconductor firm that finds itself in the geopolitical crosshairs. GPT -4, the artificial neural network which powers Chat GPT , has aced exams that serve as gateways for people to enter careers in law and medicine in America. It can generate songs, poems and essays. Other \\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u009cgenerative AI \\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u009d models can churn out digital photos, drawings and animations. Chatembodies more knowledge than any human has ever known. It can converse cogently about mineral extraction in Papua New Guinea, or about, a Taiwanese semiconductor firm that finds itself in the geopolitical crosshairs.-4, the artificial neural network which powers Chat, has aced exams that serve as gateways for people to enter careers in law and medicine in America. It can generate songs, poems and essays. Other \\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u009cgenerative\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u009d models can churn out digital photos, drawings and animations.\\n\\nAI models are being developed too quickly. GPT -4 is a type of generative AI called a large language model ( LLM ). Tech giants like Alphabet, Amazon and Nvidia have all trained their own LLM s, and given them names like P a LM , Megatron, Titan and Chinchilla. Running alongside this excitement is deep concern , inside the tech industry and beyond, that generativemodels are being developed too quickly.-4 is a type of generativecalled a large language model (). Tech giants like Alphabet, Amazon and Nvidia have all trained their owns, and given them names like, Megatron, Titan and Chinchilla.\\n\\nThe lure grows greater\\n\\nThe London tech boss says he is \\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u009cincredibly nervous about the existential threat\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u009d posed by AI , even as he pursues it, and is \\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u009cspeaking with [other] founders about it daily\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u009d. Governments in America, Europe and China have all started mulling new regulations. Prominent voices are calling for the development of artificial intelligence to be paused, lest the software somehow run out of control and damage, or even destroy, human society. To calibrate how worried or excited you should be about this technology, it helps first to understand where it came from, how it works and what the limits are to its growth.\\n\\nThe contemporary explosion of the capabilities of AI software began in the early 2010s, when a software technique called \\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u009cdeep learning\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u009d became popular. Using the magic mix of vast datasets and powerful computers running neural networks on Graphics Processing Units ( GPU s), deep learning dramatically improved computers\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u0099 abilities to recognise images, process audio and play games. By the late 2010s computers could do many of these tasks better than any human.\\n\\nBut neural networks tended to be embedded in software with broader functionality, like email clients, and non-coders rarely interacted with these AI s directly. Those that did often described their experience in near-spiritual terms. Lee Sedol, one of the world\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u0099s best players of Go, an ancient Chinese board game, retired from the game after Alphabet\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u0099s neural-net-based AlphaGo software crushed him in 2016. \\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u009cEven if I become the number one,\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u009d he said, \\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u009cthere is an entity that cannot be defeated.\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u009d\\n\\nBy working in the most human of mediums, conversation, Chat GPT is now allowing the internet-using public to experience something similar, a kind of intellectual vertigo caused by software which has improved suddenly to the point where it can perform tasks that had been exclusively in the domain of human intelligence.\\n\\nDespite that feeling of magic, an LLM is, in reality, a giant exercise in statistics. Prompt Chat GPT to finish the sentence: \\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u009cThe promise of large language models is that they\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u00a6\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u009d and you will get an immediate response. How does it work?\\n\\nFirst, the language of the query is converted from words, which neural networks cannot handle, into a representative set of numbers (see graphic). GPT -3, which powered an earlier version of Chat GPT , does this by splitting text into chunks of characters, called tokens, which commonly occur together. These tokens can be words, like \\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u009clove\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u009d or \\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u009care\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u009d, affixes, like \\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u009cdis\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u009d or \\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u009cised\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u009d, and punctuation, like \\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u009c?\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u009d. GPT -3\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u0099s dictionary contains details of 50,257 tokens.\\n\\nTokenisation The\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u008a\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u008a 464 \\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u008a\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u008apromise\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u008a\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u008a 6991 \\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u008a\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u008aof\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u008a\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u008a 286 \\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u008a\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u008alarge\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u008a\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u008a 1588 \\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u008a\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u008alanguage\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u008a\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u008a 3303 \\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u008a\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u008amodels\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u008a\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u008a 4981 \\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u008a\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u008ais\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u008a\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u008a 318 \\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u008a\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u008athat\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u008a\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u008a 326 \\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u008a\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u008athey\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u008a\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u008a 484\\n\\nGPT -3 is able to process a maximum of 2,048 tokens at a time, which is around the length of a long article in The Economist. GPT -4, by contrast, can handle inputs up to 32,000 tokens long\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u0094a novella. The more text the model can take in, the more context it can see, and the better its answers will be. There is a catch\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u0094the required computation rises non-linearly with the length of the input, meaning slightly longer inputs need much more computing power.\\n\\nThe tokens are then assigned the equivalent of definitions by placing them into a \\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u009cmeaning space\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u009d where words that have similar meanings are located in nearby areas.\\n\\nEmbedding facsimile vocabulary language tongue model replica aptitude talent speech duplicate imitation potentiality ability representation potential capability massive lookalike promise capacity great vast huge enourmous big large facsimile vocabulary language tongue model replica aptitude talent speech duplicate imitation potentiality ability representation potential capability massive lookalike promise capacity great vast huge enourmous big large vocabulary language tongue aptitude talent speech potentiality ability potential capability promise capacity facsimile model replica duplicate imitation massive representation great vast huge lookalike enourmous big large\\n\\nThe LLM then deploys its \\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u009cattention network\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u009d to make connections between different parts of the prompt. Someone reading our prompt, \\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u009cthe promise of large language models is that they\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u00a6\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u009d, would know how English grammar works and understand the concepts behind the words in the sentence. It would be obvious to them which words relate to each other\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u0094it is the model that is large, for example. An LLM , however, must learn these associations from scratch during its training phase\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u0094over billions of training runs, its attention network slowly encodes the structure of the language it sees as numbers (called \\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u009cweights\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u009d) within its neural network. If it understands language at all, an LLM only does so in a statistical, rather than a grammatical, way. It is much more like an abacus than it is like a mind.\\n\\nOnce the prompt has been processed, the LLM initiates a response. At this point, for each of the tokens in the model\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u0099s vocabulary, the attention network has produced a probability of that token being the most appropriate one to use next in the sentence it is generating. The token with the highest probability score is not always the one chosen for the response\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u0094how the LLM makes this choice depends on how creative the model has been told to be by its operators.\\n\\nThe LLM generates a word and then feeds the result back into itself. The first word is generated based on the prompt alone. The second word is generated by including the first word in the response, then the third word by including the first two generated words, and so on. This process\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u0094called autoregression\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u0094repeats until the LLM has finished\\n\\nAlthough it is possible to write down the rules for how they work, LLM s\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u0099 outputs are not entirely predictable; it turns out that these extremely big abacuses can do things which smaller ones cannot, in ways which surprise even the people who make them. Jason Wei, a researcher at Open AI , has counted 137 so-called \\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u009cemergent\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u009d abilities across a variety of different LLM s.\\n\\nThe abilities that emerge are not magic\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u0094they are all represented in some form within the LLM s\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u0099 training data (or the prompts they are given) but they do not become apparent until the LLM s cross a certain, very large, threshold in their size. At one size, an LLM does not know how to write gender-inclusive sentences in German any better than if it was doing so at random. Make the model just a little bigger, however, and all of a sudden a new ability pops out. GPT -4 passed the American Uniform Bar Examination, designed to test the skills of lawyers before they become licensed, in the 90th percentile. The slightly smaller GPT -3.5 flunked it.\\n\\nEmergent abilities are exciting, because they hint at the untapped potential of LLM s. Jonas Degrave, an engineer at DeepMind, an AI research company owned by Alphabet, has shown that Chat GPT can be convinced to act like the command line terminal of a computer, appearing to compile and run programs accurately. Just a little bigger, goes the thinking, and the models may suddenly be able to do all manner of useful new things. But experts worry for the same reason. One analysis shows that certain social biases emerge when models become large. It is not easy to tell what harmful behaviours might be lying dormant, waiting for just a little more scale in order to be unleashed.\\n\\nProcess the data\\n\\nThe recent success of LLM s in generating convincing text, as well as their startling emergent abilities, is due to the coalescence of three things: gobsmacking quantities of data, algorithms capable of learning from them and the computational power to do so (see chart). The details of GPT -4\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u0099s construction and function are not yet public, but those of GPT -3 are, in a paper called \\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u009cLanguage Models are Few-Shot Learners\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u009d, published in 2020 by Open AI .\\n\\nFaster, higher, more calculations Computing power used in training AI systems Selected systems, floating-point operations, log scale Academia Industry Research consortium GPT-4 GPT-3 Stable Diffusion Transformer Theseus 1950 60 70 80 90 2000 10 23 Sources: Sevilla et al., 2023; Our World in Data\\n\\nBefore it sees any training data, the weights in GPT -3\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u0099s neural network are mostly random. As a result, any text it generates will be gibberish. Pushing its output towards something which makes sense, and eventually something that is fluent, requires training. GPT -3 was trained on several sources of data, but the bulk of it comes from snapshots of the entire internet between 2016 and 2019 taken from a database called Common Crawl. There\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u0099s a lot of junk text on the internet, so the initial 45 terabytes were filtered using a different machine-learning model to select just the high-quality text: 570 gigabytes of it, a dataset that could fit on a modern laptop. In addition, GPT -4 was trained on an unknown quantity of images, probably several terabytes. By comparison AlexNet, a neural network that reignited image-processing excitement in the 2010s, was trained on a dataset of 1.2m labelled images, a total of 126 gigabytes\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u0094less than a tenth of the size of GPT -4\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u0099s likely dataset.\\n\\nTo train, the LLM quizzes itself on the text it is given. It takes a chunk, covers up some words at the end, and tries to guess what might go there. Then the LLM uncovers the answer and compares it to its guess. Because the answers are in the data itself, these models can be trained in a \\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u009cself-supervised\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u009d manner on massive datasets without requiring human labellers.\\n\\nThe model\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u0099s goal is to make its guesses as good as possible by making as few errors as possible. Not all errors are equal, though. If the original text is \\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u009cI love ice cream\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u009d, guessing \\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u009cI love ice hockey\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u009d is better than \\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u009cI love ice are\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u009d. How bad a guess is is turned into a number called the loss. After a few guesses, the loss is sent back into the neural network and used to nudge the weights in a direction that will produce better answers.\\n\\nTrailblazing a daze\\n\\nThe LLM \\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u0099s attention network is key to learning from such vast amounts of data. It builds into the model a way to learn and use associations between words and concepts even when they appear at a distance from each other within a text, and it allows it to process reams of data in a reasonable amount of time. Many different attention networks operate in parallel within a typical LLM and this parallelisation allows the process to be run across multiple GPU s. Older, non-attention-based versions of language models would not have been able to process such a quantity of data in a reasonable amount of time. \\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u009cWithout attention, the scaling would not be computationally tractable,\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u009d says Yoshua Bengio, scientific director of Mila, a prominent AI research institute in Quebec.\\n\\nThe sheer scale at which LLM s can process data has been driving their recent growth. GPT -3 has hundreds of layers, billions of weights, and was trained on hundreds of billions of words. By contrast, the first version of GPT , created five years ago, was just one ten-thousandth of the size.\\n\\nBut there are good reasons, says Dr Bengio, to think that this growth cannot continue indefinitely. The inputs of LLM s\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u0094data, computing power, electricity, skilled labour\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u0094cost money. Training GPT -3, for example, used 1.3 gigawatt-hours of electricity (enough to power 121 homes in America for a year), and cost Open AI an estimated $4.6m. GPT -4, which is a much larger model, will have cost disproportionately more (in the realm of $100m) to train. Since computing-power requirements scale up dramatically faster than the input data, training LLM s gets expensive faster than it gets better. Indeed, Sam Altman, the boss of Open AI , seems to think an inflection point has already arrived. On April 13th he told an audience at the Massachusetts Institute of Technology: \\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u009cI think we\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u0099re at the end of the era where it\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u0099s going to be these, like, giant, giant models. We\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u0099ll make them better in other ways.\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u009d\\n\\nBut the most important limit to the continued improvement of LLM s is the amount of training data available. GPT -3 has already been trained on what amounts to all of the high-quality text that is available to download from the internet. A paper published in October 2022 concluded that \\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u009cthe stock of high-quality language data will be exhausted soon; likely before 2026.\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u009d There is certainly more text available, but it is locked away in small amounts in corporate databases or on personal devices, inaccessible at the scale and low cost that Common Crawl allows.\\n\\nComputers will get more powerful over time, but there is no new hardware forthcoming which offers a leap in performance as large as that which came from using GPU s in the early 2010s, so training larger models will probably be increasingly expensive\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u0094perhaps why Mr Altman is not enthused by the idea. Improvements are possible, including new kinds of chips such as Google\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u0099s Tensor Processing Unit, but the manufacturing of chips is no longer improving exponentially through Moore\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u0099s law and shrinking circuits.\\n\\nThere will also be legal issues. Stability AI , a company which produces an image-generation model called Stable Diffusion, has been sued by Getty Images, a photography agency. Stable Diffusion\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u0099s training data comes from the same place as GPT -3 and GPT -4, Common Crawl, and it processes it in very similar ways, using attention networks. Some of the most striking examples of AI \\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u0099s generative prowess have been images. People on the internet are now regularly getting caught up in excitement about apparent photos of scenes that never took place: the pope in a Balenciaga jacket; Donald Trump being arrested.\\n\\nGetty points to images produced by Stable Diffusion which contain its copyright watermark, suggesting that Stable Diffusion has ingested and is reproducing copyrighted material without permission (Stability AI has not yet commented publicly on the lawsuit). The same level of evidence is harder to come by when examining Chat GPT \\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u0099s text output, but there is no doubt that it has been trained on copyrighted material. Open AI will be hoping that its text generation is covered by \\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u009cfair use\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u009d, a provision in copyright law that allows limited use of copyrighted material for \\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u009ctransformative\\u00c3\\u00a2\\u00c2\\u0080\\u00c2\\u009d purposes. That idea will probably one day be tested in court.\\n\\nA major appliance\\n\\nBut even in a scenario where LLM s stopped improving this year, and a blockbuster lawsuit drove Open AI to bankruptcy, the power of large language models would remain. The data and the tools to process it are widely available, even if the sheer scale achieved by Open AI remains expensive.\\n\\nOpen-source implementations, when trained carefully and selectively, are already aping the performance of GPT -4. This is a good thing: having the power of LLM s in many hands means that many minds can come up with innovative new applications, improving everything from medicine to the law.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cleaned_text\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"None\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cleaned_summary\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"science technology generative large creative models will transform lives and labour markets they bring enormous promise and peril the first three special articles explain how they work image george wylesol ince november when open the company which makes chat gpt first opened the chatbot the public there has been little else that the tech elite has wanted talk about this article was being written the founder london technology company messaged your correspondent unprompted say that this kind essentially all thinking about these days says the process redesigning his company valued many hundreds millions dollars around not alone gpt embodies tsmc taiwanese semiconductor firm that finds itself the geopolitical crosshairs gpt the artificial neural network which powers chat gpt has aced exams that serve gateways for people enter careers law and medicine america can generate songs poems and essays other generative models can churn out digital photos drawings and animations chatembodies more knowledge than any human has ever known can converse cogently about mineral extraction papua new guinea about taiwanese semiconductor firm that finds itself the geopolitical crosshairs the artificial neural network which powers chat has aced exams that serve gateways for people enter careers law and medicine america can generate songs poems and essays other generative models can churn out digital photos drawings and animations models are being developed too quickly gpt type generative called large language model llm tech giants like alphabet amazon and nvidia have all trained their own llm and given them names like megatron titan and chinchilla running alongside this excitement deep concern inside the tech industry and beyond that generativemodels are being developed too quickly type generativecalled large language model tech giants like alphabet amazon and nvidia have all trained their owns and given them names like megatron titan and chinchilla the lure grows greater the london tech boss says incredibly nervous about the existential threat posed even pursues and speaking with other founders about daily governments america europe and china have all started mulling new regulations prominent voices are calling for the development artificial intelligence paused lest the software somehow run out control and damage even destroy human society calibrate how worried excited you should about this technology helps first understand where came from how works and what the limits are its growth the contemporary explosion the capabilities software began the early when software technique called deep learning became popular using the magic mix vast datasets and powerful computers running neural networks graphics processing units gpu deep learning dramatically improved computers abilities recognise images process audio and play games the late computers could many these tasks better than any human but neural networks tended embedded software with broader functionality like email clients and non coders rarely interacted with these directly those that did often described their experience near spiritual terms lee sedol one the world best players ancient chinese board game retired from the game after alphabet neural net based alphago software crushed him even become the number one said there entity that cannot defeated working the most human mediums conversation chat gpt now allowing the internet using public experience something similar kind intellectual vertigo caused software which has improved suddenly the point where can perform tasks that had been exclusively the domain human intelligence despite that feeling magic llm reality giant exercise statistics prompt chat gpt finish the sentence the promise large language models that they and you will get immediate response how does work first the language the query converted from words which neural networks cannot handle into representative set numbers see graphic gpt which powered earlier version chat gpt does this splitting text into chunks characters called tokens which commonly occur together these tokens can words like love are affixes like dis ised and punctuation like gpt dictionary contains details tokens tokenisation the promise large language models that they gpt able process maximum tokens time which around the length long article the economist gpt contrast can handle inputs tokens long novella the more text the model can take the more context can see and the better its answers will there catch the required computation rises non linearly with the length the input meaning slightly longer inputs need much more computing power the tokens are then assigned the equivalent definitions placing them into meaning space where words that have similar meanings are located nearby areas embedding facsimile vocabulary language tongue model replica aptitude talent speech duplicate imitation potentiality ability representation potential capability massive lookalike promise capacity great vast huge enourmous big large facsimile vocabulary language tongue model replica aptitude talent speech duplicate imitation potentiality ability representation potential capability massive lookalike promise capacity great vast huge enourmous big large vocabulary language tongue aptitude talent speech potentiality ability potential capability promise capacity facsimile model replica duplicate imitation massive representation great vast huge lookalike enourmous big large the llm then deploys its attention network make connections between different parts the prompt someone reading our prompt the promise large language models that they would know how english grammar works and understand the concepts behind the words the sentence would obvious them which words relate each other the model that large for example llm however must learn these associations from scratch during its training phase over billions training runs its attention network slowly encodes the structure the language sees numbers called weights within its neural network understands language all llm only does statistical rather than grammatical way much more like abacus than like mind once the prompt has been processed the llm initiates response this point for each the tokens the model vocabulary the attention network has produced probability that token being the most appropriate one use next the sentence generating the token with the highest probability score not always the one chosen for the response how the llm makes this choice depends how creative the model has been told its operators the llm generates word and then feeds the result back into itself the first word generated based the prompt alone the second word generated including the first word the response then the third word including the first two generated words and this process called autoregression repeats until the llm has finished although possible write down the rules for how they work llm outputs are not entirely predictable turns out that these extremely big abacuses can things which smaller ones cannot ways which surprise even the people who make them jason wei researcher open has counted called emergent abilities across variety different llm the abilities that emerge are not magic they are all represented some form within the llm training data the prompts they are given but they not become apparent until the llm cross certain very large threshold their size one size llm does not know how write gender inclusive sentences german any better than was doing random make the model just little bigger however and all sudden new ability pops out gpt passed the american uniform bar examination designed test the skills lawyers before they become licensed the percentile the slightly smaller gpt flunked emergent abilities are exciting because they hint the untapped potential llm jonas degrave engineer deepmind research company owned alphabet has shown that chat gpt can convinced act like the command line terminal computer appearing compile and run programs accurately just little bigger goes the thinking and the models may suddenly able all manner useful new things but experts worry for the same reason one analysis shows that certain social biases emerge when models become large not easy tell what harmful behaviours might lying dormant waiting for just little more scale order unleashed process the data the recent success llm generating convincing text well their startling emergent abilities due the coalescence three things gobsmacking quantities data algorithms capable learning from them and the computational power see chart the details gpt construction and function are not yet public but those gpt are paper called language models are few shot learners published open faster higher more calculations computing power used training systems selected systems floating point operations log scale academia industry research consortium gpt gpt stable diffusion transformer theseus sources sevilla our world data before sees any training data the weights gpt neural network are mostly random result any text generates will gibberish pushing its output towards something which makes sense and eventually something that fluent requires training gpt was trained several sources data but the bulk comes from snapshots the entire internet between and taken from database called common crawl there lot junk text the internet the initial terabytes were filtered using different machine learning model select just the high quality text gigabytes dataset that could fit modern laptop addition gpt was trained unknown quantity images probably several terabytes comparison alexnet neural network that reignited image processing excitement the was trained dataset labelled images total gigabytes less than tenth the size gpt likely dataset train the llm quizzes itself the text given takes chunk covers some words the end and tries guess what might there then the llm uncovers the answer and compares its guess because the answers are the data itself these models can trained self supervised manner massive datasets without requiring human labellers the model goal make its guesses good possible making few errors possible not all errors are equal though the original text love ice cream guessing love ice hockey better than love ice are how bad guess turned into number called the loss after few guesses the loss sent back into the neural network and used nudge the weights direction that will produce better answers trailblazing daze the llm attention network key learning from such vast amounts data builds into the model way learn and use associations between words and concepts even when they appear distance from each other within text and allows process reams data reasonable amount time many different attention networks operate parallel within typical llm and this parallelisation allows the process run across multiple gpu older non attention based versions language models would not have been able process such quantity data reasonable amount time without attention the scaling would not computationally tractable says yoshua bengio scientific director mila prominent research institute quebec the sheer scale which llm can process data has been driving their recent growth gpt has hundreds layers billions weights and was trained hundreds billions words contrast the first version gpt created five years ago was just one ten thousandth the size but there are good reasons says bengio think that this growth cannot continue indefinitely the inputs llm data computing power electricity skilled labour cost money training gpt for example used gigawatt hours electricity enough power homes america for year and cost open estimated gpt which much larger model will have cost disproportionately more the realm train since computing power requirements scale dramatically faster than the input data training llm gets expensive faster than gets better indeed sam altman the boss open seems think inflection point has already arrived april told audience the massachusetts institute technology think the end the era where going these like giant giant models make them better other ways but the most important limit the continued improvement llm the amount training data available gpt has already been trained what amounts all the high quality text that available download from the internet paper published october concluded that the stock high quality language data will exhausted soon likely before there certainly more text available but locked away small amounts corporate databases personal devices inaccessible the scale and low cost that common crawl allows computers will get more powerful over time but there new hardware forthcoming which offers leap performance large that which came from using gpu the early training larger models will probably increasingly expensive perhaps why altman not enthused the idea improvements are possible including new kinds chips such google tensor processing unit but the manufacturing chips longer improving exponentially through moore law and shrinking circuits there will also legal issues stability company which produces image generation model called stable diffusion has been sued getty images photography agency stable diffusion training data comes from the same place gpt and gpt common crawl and processes very similar ways using attention networks some the most striking examples generative prowess have been images people the internet are now regularly getting caught excitement about apparent photos scenes that never took place the pope balenciaga jacket donald trump being arrested getty points images produced stable diffusion which contain its copyright watermark suggesting that stable diffusion has ingested and reproducing copyrighted material without permission stability has not yet commented publicly the lawsuit the same level evidence harder come when examining chat gpt text output but there doubt that has been trained copyrighted material open will hoping that its text generation covered fair use provision copyright law that allows limited use copyrighted material for transformative purposes that idea will probably one day tested court major appliance but even scenario where llm stopped improving this year and blockbuster lawsuit drove open bankruptcy the power large language models would remain the data and the tools process are widely available even the sheer scale achieved open remains expensive open source implementations when trained carefully and selectively are already aping the performance gpt this good thing having the power llm many hands means that many minds can come with innovative new applications improving everything from medicine the law \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_text =np.array(df['cleaned_text'])\n",
        "cleaned_summary=np.array(df['cleaned_summary'])\n",
        "\n",
        "short_text=[]\n",
        "short_summary=[]\n",
        "\n",
        "for i in range(len(cleaned_text)):\n",
        "    if(len(cleaned_summary[i].split())<=63 and len(cleaned_text[i].split())<=600):\n",
        "        short_text.append(cleaned_text[i])\n",
        "        short_summary.append(cleaned_summary[i])\n",
        "\n",
        "data=pd.DataFrame({'text':short_text,'summary':short_summary})"
      ],
      "metadata": {
        "id": "xLgtt0ulXPsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "tDUTwRdvXVUh",
        "outputId": "d0c0608c-af16-40f7-e231-ae280158b08d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   text                                            summary\n",
              "0  None  sostok why did this happen please make sure yo..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8736c8e6-8ccf-463d-b8eb-1c5590b489b7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>None</td>\n",
              "      <td>sostok why did this happen please make sure yo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8736c8e6-8ccf-463d-b8eb-1c5590b489b7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8736c8e6-8ccf-463d-b8eb-1c5590b489b7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8736c8e6-8ccf-463d-b8eb-1c5590b489b7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"None\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"summary\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"sostok why did this happen please make sure your browser supports javascript and cookies and that you are not blocking them from loading for more information you can review our terms service and cookie policy  eostok\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['summary']=data['summary'].apply(lambda x:'sostok '+x+' eostok')\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "MypgzRo3jdhp",
        "outputId": "879e9944-f792-46a7-9caa-ba2177534805"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   text                                            summary\n",
              "0  None  sostok sostok why did this happen please make ..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fcc96d46-fd1d-4c66-88d2-63ba5936acfd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>None</td>\n",
              "      <td>sostok sostok why did this happen please make ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fcc96d46-fd1d-4c66-88d2-63ba5936acfd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fcc96d46-fd1d-4c66-88d2-63ba5936acfd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fcc96d46-fd1d-4c66-88d2-63ba5936acfd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"None\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"summary\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"sostok sostok why did this happen please make sure your browser supports javascript and cookies and that you are not blocking them from loading for more information you can review our terms service and cookie policy  eostok eostok\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    }
  ]
}